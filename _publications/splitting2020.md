---
title: "Distributed Proximal Splitting Algorithms with Rates and Acceleration"
collection: publication
permalink: /publication/splitting2020
excerpt: 'Laurent Condat, Grigory Malinovsky, Peter Richt√°rik'
date: 2020-12-11
venue: 'The 12th Annual Workshop on Optimization for Machine Learning (NeurIPS 2020 Workshop OPT2020), spotlight!'
---
[PDF](https://arxiv.org/pdf/2010.00952.pdf), [Cite](https://scholar.googleusercontent.com/scholar.bib?q=info:qe_G0ZhAwXEJ:scholar.google.com/&output=citation&scisdr=CgXs1Zy1EKfp3RDzxU0:AAGBfm0AAAAAX-r23U0xNE0QYPA9OEoXk6nGFOfzaONP&scisig=AAGBfm0AAAAAX-r23TeAqSVxZEwxdL4jx28qNfCNrmJl&scisf=4&ct=citation&cd=-1&hl=en), [Poster](https://opt-ml.org/posters/2020/poster_31.png), [arXiv](https://arxiv.org/abs/2010.00952), [OPT2020](https://opt-ml.org/papers.html), [NeurIPS](https://nips.cc/Conferences/2020/Schedule?showEvent=16149)  

Abstract:
======
We propose new generic distributed proximal splitting algorithms, well suited for large-scale convex nonsmooth optimization. We derive sublinear and linear convergence results with new noner- godic rates, as well as new accelerated versions of the algorithms, using varying stepsizes.

